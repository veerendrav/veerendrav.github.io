---
layout: distill
published: false
title: Reinforcement Learning Research Papers - Notes[0/100]
description: Notes on the selected research papers in Reinforcement Learning
tags: paper-notes
categories: paper-notes
giscus_comments: true
date: 2024-12-19
featured: false
mermaid:
  enabled: true
  zoomable: true
code_diff: true
map: true
chart:
  chartjs: true
  echarts: true
  vega_lite: true
tikzjax: true
typograms: true

authors:
  - name: Veerendrababu Vakkapatla
    url: "https://veerendrav.github.io"
    affiliations:
      name: IIT Bombay

bibliography: 2024-12-19-pr-set-1.bib

# Optionally, you can add a table of contents to your post.
# NOTES:
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
#   - we may want to automate TOC generation in the future using
#     jekyll-toc plugin (https://github.com/toshimaru/jekyll-toc).
toc:
  - name: Navix
  - name: RLiable
    # if a section has subsections, you can add them as follows:
    # subsections:
    #   - name: Example Child Subsection 1
    #   - name: Example Child Subsection 2
  - name: Streaming Deep RL
  - name: Parallel Q-learning
  - name: HPO for RL
  - name: Plasticity in Deep RL
  - name: Deep bisimulation for Control
  - name: Reward centering
  - name: Swift-TD
  - name: MaxInfoRL

# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

## Navix

- <u> <b>Paper</b> </u> : [Navix: Scaling MiniGrid Environments with JAX](https://arxiv.org/abs/2407.19396)

  - ***The Problem*** : Accelerating RL environments on GPU
  - ***Why is this problem important?*** : Complex environments require more agent-environment interactions to learn due to their high observation space or stochastic environment dynamics. Agent part has already been  accelerated on GPU due to advancements in modern neural network libraries for distributed training, environment part is still not accelerated and not compatible for distributed training. Traditionally these environments run on CPUwhich induces unnecessary computation and communication overhead.
  - ***Proposed Solution(or main idea)*** : MiniGrid Environments are heavily used to study many aspects of Deep RL such as exploration,curriculum learning,planning,representation learning,meta and transfer learning in the literature. The paper Re-implemented MiniGrid environments in JAX to leverage GPU acceleration. 
  - ***What are the key results?*** : MiniGrid-JAX is 10x faster with an increased throughput of 10<sup>6</sup>x than original CPU implementation of MiniGrid turning 1 week experiments into 15min ones. 
  - ***What are the limitations?*** :
  - ***What future work?*** :
  - ***Related work***




---

## RLiable

---